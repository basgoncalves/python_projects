{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users\n",
      "{'side_step_left_1': {'some_attribute': 'value'}, 'side_step_right_1': {'another_attribute': 123}, 'sprint_1': {'speed': 'fast'}}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "class User:\n",
    "    def __init__(self, username, trial_attributes=None, files=None):\n",
    "        self.username = username\n",
    "        self.trial_attributes = trial_attributes or {}  # Dictionary to store trial attributes\n",
    "        self.files = files or {}  # Dictionary to store file paths and status\n",
    "\n",
    "    def add_trial_attribute(self, trial_name, attributes):\n",
    "        \"\"\"Adds trial attributes to the user's trial_attributes dictionary.\"\"\"\n",
    "        self.trial_attributes[trial_name] = attributes\n",
    "\n",
    "    def add_file(self, filename, status):\n",
    "        \"\"\"Adds a file and its status to the user's files dictionary.\"\"\"\n",
    "        self.files[filename] = status\n",
    "\n",
    "    def to_json(self, filepath):\n",
    "        \"\"\"Saves the user object to a JSON file.\"\"\"\n",
    "        data = {\n",
    "            \"username\": self.username,\n",
    "            \"trial_attributes\": self.trial_attributes,\n",
    "            \"files\": self.files\n",
    "        }\n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "    @classmethod\n",
    "    def from_json(cls, filepath):\n",
    "        \"\"\"Loads a user object from a JSON file.\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            data = json.load(f)\n",
    "        return cls(data[\"username\"], data[\"trial_attributes\"], data[\"files\"])\n",
    "\n",
    "    @classmethod\n",
    "    def load_from_directory(cls, directory):\n",
    "        \"\"\"Loads all files from a directory and creates a user object.\"\"\"\n",
    "        username = os.path.basename(directory)  # Assumes directory name is the username\n",
    "        user = cls(username)\n",
    "\n",
    "        for filename in os.listdir(directory):\n",
    "            filepath = os.path.join(directory, filename)\n",
    "            if os.path.isfile(filepath):\n",
    "                # You can add logic here to determine the file status (e.g., 'U' or None)\n",
    "                # For now, let's assume all files are 'U'\n",
    "                user.add_file(filename, 'U')\n",
    "\n",
    "        return user\n",
    "\n",
    "# Example Usage (based on the image):\n",
    "\n",
    "# 1. Create a User object from the directory structure\n",
    "current_directory = os.getcwd()\n",
    "user_directory = os.path.join(current_directory, \"users\")\n",
    "user = User.load_from_directory(user_directory)\n",
    "\n",
    "# 2. Add trial attributes (if you have them)\n",
    "user.add_trial_attribute(\"side_step_left_1\", {\"some_attribute\": \"value\"})\n",
    "user.add_trial_attribute(\"side_step_right_1\", {\"another_attribute\": 123})\n",
    "user.add_trial_attribute(\"sprint_1\", {\"speed\": \"fast\"})\n",
    "\n",
    "# 3. Save the User object to a JSON file\n",
    "settings_file = os.path.join(current_directory, \"settings.json\")\n",
    "user.to_json(settings_file)\n",
    "\n",
    "# 4. Load the User object from the JSON file\n",
    "loaded_user = User.from_json(settings_file)\n",
    "\n",
    "# 5. Access the user's attributes and files\n",
    "print(loaded_user.username)\n",
    "print(loaded_user.trial_attributes)\n",
    "print(loaded_user.files)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create classes and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import c3d\n",
    "import xml.etree.ElementTree as ET\n",
    "import opensim as osim\n",
    "import json\n",
    "import msk_modelling_python as msk\n",
    "\n",
    "class File:\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.name = os.path.basename(path)\n",
    "        self.extension = os.path.splitext(path)[1]\n",
    "        \n",
    "        if not os.path.isfile(path):\n",
    "            print(f\"\\033[93mFile not found: {path}\\033[0m\")\n",
    "            return        \n",
    "        \n",
    "        try:\n",
    "            endheader_line = msk.classes.osimSetup.find_file_endheader_line(path)\n",
    "        except:\n",
    "            print(f\"Error finding endheader line for file: {path}\")\n",
    "            endheader_line = 0\n",
    "        # Read file based on extension\n",
    "        try:\n",
    "            if self.extension == '.csv':\n",
    "                self.data = msk.pd.read_csv(path)\n",
    "            elif self.extension == '.json':\n",
    "                self.data = msk.bops.import_json_file(path)\n",
    "            elif self.extension == '.xml':\n",
    "                self.data = msk.bops.XMLTools.load(path)\n",
    "            else:\n",
    "                try:\n",
    "                    self.data = msk.pd.read_csv(path, sep=\"\\t\", skiprows=endheader_line)\n",
    "                except:\n",
    "                    self.data = None\n",
    "                    \n",
    "            # add time range for the data\n",
    "            try:\n",
    "                self.time_range = [self.data['time'].iloc[0], self.data['time'].iloc[-1]]\n",
    "                try:\n",
    "                    self.time_range = [self.data['Time'].iloc[0], self.data['Time'].iloc[-1]]\n",
    "                except:\n",
    "                    pass\n",
    "            except:\n",
    "                self.time_range = None\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error reading file: {path}\")\n",
    "            print(e)\n",
    "            self.data = None\n",
    "            self.time_range = None\n",
    "            \n",
    "class Trial:\n",
    "    '''\n",
    "    Class to store trial information and file paths, and export files to OpenSim format\n",
    "    \n",
    "    Inputs: trial_path (str) - path to the trial folder\n",
    "    \n",
    "    Attributes:\n",
    "    path (str) - path to the trial folder\n",
    "    name (str) - name of the trial folder\n",
    "    og_c3d (str) - path to the original c3d file\n",
    "    c3d (str) - path to the c3d file in the trial folder\n",
    "    markers (str) - path to the marker trc file\n",
    "    grf (str) - path to the ground reaction force mot file\n",
    "    ...\n",
    "    \n",
    "    Methods: use dir(Trial) to see all methods\n",
    "    \n",
    "    '''\n",
    "    def __init__(self, trial_path=None):  \n",
    "        \n",
    "        if not trial_path:\n",
    "            trial_path = msk.ui.select_folder('Select trial folder')\n",
    "                  \n",
    "        self.path = trial_path\n",
    "        self.name = os.path.basename(self.path)\n",
    "        self.subject = os.path.basename(os.path.dirname(self.path))\n",
    "        self.c3d = os.path.join(os.path.dirname(self.path), self.name + '.c3d')\n",
    "        self.markers = File(os.path.join(self.path,'markers_experimental.trc'))\n",
    "        self.grf = File(os.path.join(self.path,'Visual3d_SIMM_grf.mot'))\n",
    "        self.emg_csv = os.path.join(self.path,'processed_emg_signals.csv')\n",
    "        self.emg = File(os.path.join(self.path,'processed_emg_signals.mot'))\n",
    "        self.ik = File(os.path.join(self.path,'Visual3d_SIMM_input.mot'))\n",
    "        self.id = File(os.path.join(self.path,'inverse_dynamics.sto'))\n",
    "        self.so_force = File(os.path.join(self.path,'Results_SO_and_MA', f'{self.subject}_StaticOptimization_force.sto'))\n",
    "        self.so_activation = File(os.path.join(self.path, 'Results_SO_and_MA', f'{self.subject}_StaticOptimization_activation.sto'))\n",
    "        self.jra = File(os.path.join(self.path,'joint_reacton_loads.sto'))\n",
    "        \n",
    "        # load muscle analysis files\n",
    "        self.ma_targets = ['_MomentArm_', '_Length.sto']\n",
    "        self.ma_files = []\n",
    "        try:\n",
    "            files = os.listdir(os.path.join(self.path, 'Results_SO_and_MA'))\n",
    "            for file in files:\n",
    "                if file.__contains__(self.ma_targets[0]) or file.__contains__(self.ma_targets[1]):\n",
    "                    self.ma_files.append(File(os.path.join(self.path, 'Results_SO_and_MA', file)))\n",
    "        except:\n",
    "            self.ma_files = None\n",
    "                    \n",
    "        # settings files\n",
    "        self.grf_xml = File(os.path.join(self.path,'GRF_Setup.xml'))\n",
    "        self.actuators_so = File(os.path.join(self.path,'actuators_SO.xml'))\n",
    "        \n",
    "        self.settings_json = File(os.path.join(self.path,'settings.json'))\n",
    "                             \n",
    "    def check_files(self):\n",
    "        '''\n",
    "        Output: True if all files exist, False if any file is missing\n",
    "        '''\n",
    "        files = self.__dict__.values()\n",
    "        all_files_exist = True\n",
    "        for file in files:\n",
    "            try:\n",
    "                if not os.path.isfile(file):\n",
    "                    print('File not found: ' + file)\n",
    "                    all_files_exist = False\n",
    "            except:\n",
    "                pass\n",
    "        return all_files_exist\n",
    "    \n",
    "    def header_mot(self,df,name):\n",
    "\n",
    "            num_rows = len(df)\n",
    "            num_cols = len(df.columns) \n",
    "            inital_time = df['Time'].iloc[0]\n",
    "            final_time = df['Time'].iloc[-1]\n",
    "            df_range = f'{inital_time}  {final_time}'\n",
    "\n",
    "\n",
    "            return f'name {name}\\n datacolumns {num_cols}\\n datarows {num_rows}\\n range {df_range} \\n endheader'\n",
    "        \n",
    "    def csv_to_mot(self):\n",
    "        \n",
    "        emg_data = msk.bops.pd.read_csv(self.emg_csv)\n",
    "\n",
    "        fs = int(1/(emg_data['time'][1] - emg_data['time'][0]))\n",
    "\n",
    "        time = emg_data['time']\n",
    "\n",
    "        # start time from new time point\n",
    "        start_time = time.iloc[0]\n",
    "        end_time = time.iloc[-1] - time.iloc[0] + start_time\n",
    "\n",
    "        num_samples = len(emg_data)\n",
    "        #num_samples = int((end_time - start_time) / (1/fs))\n",
    "        new_time = np.linspace(start_time, end_time, num_samples)\n",
    "\n",
    "        emg_data['time'] = new_time\n",
    "\n",
    "        # Define a new file path \n",
    "        new_file_path = os.path.join(self.emg_csv.replace('.csv', '.mot'))\n",
    "\n",
    "        # Save the modified DataFrame\n",
    "        emg_data.to_csv(new_file_path, index=False)  # index=False prevents adding an extra index column\n",
    "\n",
    "        # save to mot\n",
    "        header = self.header_mot(emg_data, \"processed_emg_signals\")\n",
    "\n",
    "        mot_path = new_file_path.replace('.csv','.mot')\n",
    "        with open(mot_path, 'w') as f:\n",
    "            f.write(header + '\\n')  \n",
    "            # print column names \n",
    "            f.write('\\t'.join(map(str, emg_data.columns)) + '\\n')\n",
    "            for index, row in emg_data.iterrows():\n",
    "                f.write('\\t'.join(map(str, row.values)) + '\\n')  \n",
    "        \n",
    "        print(f\"File saved: {mot_path}\")\n",
    "\n",
    "    def create_settings_json(self, overwrite=False):\n",
    "        if os.path.isfile(self.settings_json) and not overwrite:\n",
    "            print('settings.json already exists')\n",
    "            return\n",
    "        \n",
    "        settings_dict = self.__dict__\n",
    "        msk.bops.save_json_file(settings_dict, self.settings_json)\n",
    "        print('trial settings.json created in ' + self.path)\n",
    "    \n",
    "    def exportC3D(self):\n",
    "        msk.bops.c3d_osim_export(self.og_c3d) \n",
    "\n",
    "    def change_grf_xml_path(self):\n",
    "\n",
    "        try:\n",
    "            self.tree = ET.parse(self.grf_xml.path)\n",
    "            self.root = self.tree.getroot()\n",
    "            self.root.find('.//datafile').text = self.grf.path\n",
    "            \n",
    "            self.tree.write(self.grf_xml.path)\n",
    "            \n",
    "            print(f\"GRF file path updated in {self.grf_xml.path}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading XML file: {e}\")\n",
    "            return None\n",
    "\n",
    "    def save_json_file(self, data=None, jsonFilePath=None):\n",
    "        if not jsonFilePath:\n",
    "            jsonFilePath = self.settings_json\n",
    "        \n",
    "        if not data:\n",
    "            data = self\n",
    "            \n",
    "        data = data.__dict__\n",
    "\n",
    "        with open(jsonFilePath, 'w') as f:\n",
    "            json.dump(data, f, indent=4)\n",
    "\n",
    "        json_data = msk.bops.import_json_file(jsonFilePath)\n",
    "        return json_data\n",
    "    \n",
    "    def to_json(self):\n",
    "        msk.bops.save_json_file(self.__dict__, jsonFilePath = self.settings_json)\n",
    "        print('settings.json created in ' + self.settings_json)\n",
    "    \n",
    "    def run_IK(osim_modelPath, trc_file, resultsDir):\n",
    "        '''\n",
    "        Function to run Inverse Kinematics using the OpenSim API.\n",
    "        \n",
    "        Inputs:\n",
    "                osim_modelPath(str): path to the OpenSim model file\n",
    "                trc_file(str): path to the TRC file\n",
    "                resultsDir(str): path to the directory where the results will be saved\n",
    "        '''\n",
    "\n",
    "        # Load the TRC file\n",
    "        import pdb; pdb.set_trace()\n",
    "        tuple_data = import_trc_file(trc_file)\n",
    "        df = pd.DataFrame.from_records(tuple_data, columns=[x[0] for x in tuple_data])\n",
    "        column_names = [x[0] for x in tuple_data]\n",
    "        if len(set(column_names)) != len(column_names):\n",
    "            print(\"Error: Duplicate column names found.\")\n",
    "        # Load the model\n",
    "        osimModel = osim.Model(osim_modelPath)                              \n",
    "        state = osimModel.initSystem()\n",
    "\n",
    "        # Define the time range for the analysis\n",
    "        \n",
    "        initialTime = TRCData.getIndependentColumn()\n",
    "        finalTime = TRCData.getLastTime()\n",
    "\n",
    "        # Create the inverse kinematics tool\n",
    "        ikTool = osim.InverseKinematicsTool()\n",
    "        ikTool.setModel(osimModel)\n",
    "        ikTool.setStartTime(initialTime)\n",
    "        ikTool.setEndTime(finalTime)\n",
    "        ikTool.setMarkerDataFileName(trc_file)\n",
    "        ikTool.setResultsDir(resultsDir)\n",
    "        ikTool.set_accuracy(1e-6)\n",
    "        ikTool.setOutputMotionFileName(os.path.join(resultsDir, \"ik.mot\"))\n",
    "\n",
    "        # print setup\n",
    "        ikTool.printToXML(os.path.join(resultsDir, \"ik_setup.xml\"))         \n",
    "\n",
    "        # Run inverse kinematics\n",
    "        print(\"running ik...\")                                             \n",
    "        ikTool.run()\n",
    "\n",
    "    def run_inverse_kinematics(model_file, marker_file, output_motion_file):\n",
    "        # Load model and create an InverseKinematicsTool\n",
    "        model = osim.Model(model_file)\n",
    "        ik_tool = osim.InverseKinematicsTool()\n",
    "\n",
    "        # Set the model for the InverseKinematicsTool\n",
    "        ik_tool.setModel(model)\n",
    "\n",
    "        # Set the marker data file for the InverseKinematicsTool\n",
    "        ik_tool.setMarkerDataFileName(marker_file)\n",
    "\n",
    "        # Specify output motion file\n",
    "        ik_tool.setOutputMotionFileName(output_motion_file)\n",
    "\n",
    "        # Save setup file\n",
    "        ik_tool.printToXML('setup_ik.xml')\n",
    "\n",
    "        # Run Inverse Kinematics\n",
    "        ik_tool.run()\n",
    "\n",
    "    def run_ID(self, osim_modelPath, coordinates_file, external_loads_file, output_file, LowpassCutoffFrequency=6, run_tool=True):\n",
    "        \n",
    "        try: \n",
    "            model = osim.Model(osim_modelPath)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {osim_modelPath}\")\n",
    "            print(e)\n",
    "            return\n",
    "        \n",
    "        results_folder = os.path.dirname(output_file)\n",
    "        \n",
    "        # Setup for excluding muscles from ID\n",
    "        exclude = osim.ArrayStr()\n",
    "        exclude.append(\"Muscles\")\n",
    "        # Setup for setting time range\n",
    "        IKData = osim.Storage(coordinates_file)\n",
    "\n",
    "        # Create inverse dynamics tool, set parameters and run\n",
    "        id_tool = osim.InverseDynamicsTool()\n",
    "        id_tool.setModel(model)\n",
    "        id_tool.setCoordinatesFileName(coordinates_file)\n",
    "        id_tool.setExternalLoadsFileName(external_loads_file)\n",
    "        id_tool.setOutputGenForceFileName(output_file)\n",
    "        id_tool.setLowpassCutoffFrequency(LowpassCutoffFrequency)\n",
    "        id_tool.setStartTime(IKData.getFirstTime())\n",
    "        id_tool.setEndTime(IKData.getLastTime())\n",
    "        id_tool.setExcludedForces(exclude)\n",
    "        id_tool.setResultsDir(results_folder)\n",
    "        id_tool.printToXML(os.path.join(results_folder, \"setup_ID.xml\"))\n",
    "        \n",
    "        if run_tool:\n",
    "            id_tool.run()\n",
    "    \n",
    "    def export_analog(self, c3dFilePath=None):\n",
    "        if not c3dFilePath:\n",
    "            print('C3D file path not provided')\n",
    "            return\n",
    "        \n",
    "        reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "        # get analog labels, trimmed and replace '.' with '_'\n",
    "        analog_labels = reader.analog_labels\n",
    "        analog_labels = [label.strip() for label in analog_labels]\n",
    "        analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "\n",
    "        # get analog labels, trimmed and replace '.' with '_'\n",
    "        fs = reader.analog_rate\n",
    "\n",
    "        # add time to dataframe\n",
    "        first_frame = reader.first_frame / fs\n",
    "        final_time = (reader.first_frame + reader.frame_count-1) / fs\n",
    "        time = msk.np.arange(first_frame / fs, final_time, 1 / fs)  \n",
    "        num_frames = len(time)\n",
    "        df = msk.pd.DataFrame(index=range(num_frames),columns=analog_labels)\n",
    "        df['time'] = time\n",
    "\n",
    "        # move time to first column\n",
    "        cols = df.columns.tolist()\n",
    "        cols = cols[-1:] + cols[:-1]\n",
    "        df = df[cols] \n",
    "\n",
    "        # loop through frames and add analog data to dataframe\n",
    "        for i_frame, points, analog in reader.read_frames():\n",
    "            \n",
    "            # get row number and print loading bar\n",
    "            i_row = i_frame - reader.first_frame\n",
    "            # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "            \n",
    "            # convert analog data to list\n",
    "            analog_list  = analog.data.tolist()\n",
    "            \n",
    "            # loop through analog channels and add to dataframe\n",
    "            for i_channel in range(len(analog_list)):\n",
    "                channel_name = analog_labels[i_channel]\n",
    "                \n",
    "                # add channel to dataframe\n",
    "                df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "                \n",
    "        # save emg data to csv\n",
    "        df.to_csv(self.emg_csv)\n",
    "        \n",
    "        # save to mot\n",
    "        self.csv_to_mot()\n",
    "    \n",
    "class openSim:\n",
    "    def __init__(self, leg = 'l', subjects =['PC002','PC003','PC006', 'PC013', 'TD006', 'TD013', 'TD017', 'TD021', 'TD023', 'TD026'], trials_to_load = ['trial1','trial2','trial3','normal1', 'normal2', 'normal3', 'crouch1', 'crouch2', 'crouch3'], trial_number = 1):\n",
    "        try:\n",
    "            self.code_path = os.path.dirname(__file__)\n",
    "        except:\n",
    "            self.code_path = os.getcwd()\n",
    "        \n",
    "        self.simulations_path = os.path.join(os.path.dirname(self.code_path), 'Simulations')\n",
    "        self.subjects = {}\n",
    "        \n",
    "        for subject in subjects:\n",
    "            self.subjects[subject] = {}\n",
    "            self.subjects[subject]['model'] = os.path.join(self.simulations_path, subject, subject + '_scaled.osim')\n",
    "            \n",
    "            for trial in trials_to_load:                \n",
    "                self.trial_path = os.path.join(self.simulations_path, subject, f'{trial}_{leg}{trial_number}')\n",
    "                try:\n",
    "                    trial = Trial(self.trial_path)\n",
    "                    self.subjects[subject][trial.name] = trial \n",
    "                except Exception as e:\n",
    "                    self.subjects[subject][trial] =  None\n",
    "                    # print(f\"Error loading trial: {self.trial_path}\")\n",
    "                    # print(e)\n",
    "        \n",
    "\n",
    "        self.ik_columns = [\"hip_flexion_\" + leg, \"hip_adduction_\" + leg, \"hip_rotation_\" + leg, \"knee_angle_\" + leg, \"ankle_angle_\" + leg]\n",
    "        self.id_columns = [\"hip_flexion_\" + leg + \"_moment\", \"hip_adduction_\" + leg + \"_moment\", \"hip_rotation_\" + leg + \"_moment\", \"knee_angle_\" + leg + \"_moment\", \"ankle_angle_\" + leg + \"_moment\"]\n",
    "        self.force_columns = [\"add_long_\" + leg, \"rect_fem_\" + leg, \"med_gas_\" + leg, \"semiten_\" + leg,\"tib_ant_\" + leg]\n",
    "\n",
    "\n",
    "        self.titles = [\"Hip Flexion\", \"Hip Adduction\", \"Hip Rotation\", \"Knee Flexion\", \"Ankle Plantarflexion\"]\n",
    "        self.titles_muscles = [\"Adductor Longus\", \"Rectus Femoris\", \"Medial Gastrocnemius\", \"Semitendinosus\", \"Tibialis Anterior\"]\n",
    "\n",
    "    # Time Normalisation Function \n",
    "    def time_normalised_df(self, df, fs=None):\n",
    "        if not isinstance(df, msk.pd.DataFrame):\n",
    "            raise Exception('Input must be a pandas DataFrame')\n",
    "        \n",
    "        if not fs:\n",
    "            try:\n",
    "                fs = 1 / (df['time'][1] - df['time'][0])  # Ensure correct time column\n",
    "            except KeyError:\n",
    "                raise Exception('Input DataFrame must contain a column named \"time\"')\n",
    "            \n",
    "        normalised_df = msk.pd.DataFrame(columns=df.columns)\n",
    "\n",
    "        for column in df.columns:\n",
    "            if column == 'time':  # Skip time column\n",
    "                continue\t\n",
    "            normalised_df[column] = msk.np.zeros(101)\n",
    "\n",
    "            currentData = df[column].dropna()  # Remove NaN values\n",
    "\n",
    "            timeTrial = msk.np.linspace(0, len(currentData) / fs, len(currentData))  # Original time points\n",
    "            Tnorm = msk.np.linspace(0, timeTrial[-1], 101)  # Normalize to 101 points\n",
    "\n",
    "            normalised_df[column] = msk.np.interp(Tnorm, timeTrial, currentData)  # Interpolate\n",
    "\n",
    "        return normalised_df\n",
    "\n",
    "    def plot_single_trial(self, show = False):\n",
    "        #Read .mot files\n",
    "        with open(self.mot_file, \"r\") as file:\n",
    "            lines = file.readlines()\n",
    "\n",
    "        # Find the line where actual data starts (usually after 'endheader')\n",
    "        for i, line in enumerate(lines):\n",
    "            if \"endheader\" in line:\n",
    "                start_row = i + 1  # Data starts after this line\n",
    "                break\n",
    "        else:\n",
    "            start_row = 0  # If 'endheader' is not found, assume no header\n",
    "\n",
    "        # Load data using Pandas\n",
    "        self.df_ik = msk.pd.read_csv(self.mot_file, delim_whitespace=True, start_row=start_row)\n",
    "        self.df_id = msk.pd.read_csv(self.id_file, sep=\"\\t\", start_row=6)\n",
    "        self.df_force = msk.pd.read_csv(self.force_file, sep=\"\\t\", start_row=14)\n",
    "\n",
    "        # Apply normalisation to both IK (angles) and ID (moments) data\n",
    "        self.df_ik_normalized = self.time_normalised_df(df=self.df_ik)\n",
    "        self.df_id_normalized = self.time_normalised_df(df=self.df_id)\n",
    "        self.df_force_normalized = self.time_normalised_df(df=self.df_force)\n",
    "\n",
    "        # Ensure time is normalized to 101 points\n",
    "        time_normalized = msk.np.linspace(0, 100, 101)  \n",
    " \n",
    "        # select the specified columns         \n",
    "        self.ik_data = self.df_ik_normalized[self.ik_columns]\n",
    "        self.id_data = self.df_id_normalized[self.id_columns]\n",
    "        self.force_data = self.df_force_normalized[self.force_columns]\n",
    "            \n",
    "        # Define the layout \n",
    "        fig, axes = plt.subplots(2, 5, figsize=(15, 4)) \n",
    "\n",
    "        #Plot IK (angles)\n",
    "        for i, col in enumerate(self.ik_columns):\n",
    "            ax = axes[0,i]\n",
    "            ax.plot(time_normalized, self.ik_data[col], color='red')  # Main curve\n",
    "            ax.set_title(self.titles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Angle (deg)\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        #Plot ID (moments)\n",
    "        for i, col in enumerate(self.id_columns):\n",
    "            ax = axes[1,i]\n",
    "            ax.plot(time_normalized, self.id_data[col], color='blue')  # Main curve\n",
    "            ax.set_title(self.titles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Moment (Nm)\")\n",
    "            ax.set_xlabel(\"% Gait Cycle\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "\n",
    "        # PLOT MUSCLE FORCES \n",
    "        fig, axes = plt.subplots(nrows=1, ncols=5, figsize=(15, 4), sharex=True)\n",
    "\n",
    "        for i, col in enumerate(self.force_columns):\n",
    "            ax = axes[i]\n",
    "            ax.plot(time_normalized, self.force_data[col], color='green')\n",
    "            ax.set_title(self.titles_muscles[i])\n",
    "            if i == 0:\n",
    "                ax.set_ylabel(\"Force (N)\")\n",
    "            ax.set_xlabel(\"% Gait Cycle\")\n",
    "            ax.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        if show:\n",
    "            plt.show()\n",
    "\n",
    "    def plot_multiple_trials(self, show=False):\n",
    "        self.df_ik_list = []  # Store loaded DataFrames\n",
    "        \n",
    "        for subject in self.subjects:\n",
    "            for trial in self.subjects[subject]:\n",
    "                trial_obj = self.subjects[subject][trial]\n",
    "                if trial_obj:\n",
    "                    self.df_ik_list.append(trial_obj.ik.data)\n",
    "                    \n",
    "        for file in self.mot_files:  # Loop through each file\n",
    "            with open(file, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "\n",
    "            # Load data using Pandas\n",
    "            df = msk.pd.read_csv(file, delim_whitespace=True, skiprows=5)\n",
    "            self.df_ik_list.append(df)\n",
    "\n",
    "        # Normalize all loaded IK data\n",
    "        self.df_ik_normalized_list = []  # Store normalized DataFrames\n",
    "\n",
    "        for df in self.df_ik_list:  # Loop through each loaded DataFrame\n",
    "            df_normalized = self.time_normalised_df(df=df)  # Apply normalization\n",
    "            self.df_ik_normalized_list.append(df_normalized)  # Store normalized DataFrame\n",
    "\n",
    "        # Ensure time is normalized to 101 points\n",
    "        time_normalized = msk.np.linspace(0, 100, 101)\n",
    "\n",
    "        # Select the specified columns from normalized data\n",
    "        self.ik_data_list = []  # Store DataFrames with only the required columns\n",
    "\n",
    "        for df_normalized in self.df_ik_normalized_list:  # Loop through each normalized DataFrame\n",
    "            if set(self.ik_columns).issubset(df_normalized.columns):  # Check if columns exist\n",
    "                self.ik_data_list.append(df_normalized[self.ik_columns])  # Select only specified columns\n",
    "            else:\n",
    "                print(\"Warning: Some specified columns are missing in a file.\")\n",
    "\n",
    "        # Plot mean and sd\n",
    "        # Check if IK data exists\n",
    "        if not self.ik_data_list:\n",
    "            print(\"No IK data available to plot!\")\n",
    "        else:\n",
    "            # Convert list of DataFrames to a single NumPy array\n",
    "            combined_df = np.array([df.values for df in self.ik_data_list])  # Shape: (num_trials, num_timepoints, num_columns)\n",
    "\n",
    "            # Check if data is properly structured\n",
    "            if combined_df.shape[0] < 2:\n",
    "                print(\"Not enough trials to calculate mean and standard deviation!\")\n",
    "            else:\n",
    "                # Compute Mean and Standard Deviation\n",
    "                mean_values = np.mean(combined_df, axis=0)\n",
    "                std_values = np.std(combined_df, axis=0)\n",
    "\n",
    "                # Normalize time from 0 to 100% Gait Cycle\n",
    "                time_values = np.linspace(0, 100, combined_df.shape[1])\n",
    "\n",
    "                # Create a shared figure for all subplots\n",
    "                fig, axes = plt.subplots(nrows=1, ncols=len(self.ik_columns), figsize=(20, 5), sharex=True)\n",
    "\n",
    "                if len(self.ik_columns) == 1:\n",
    "                    axes = [axes]  # If only one column, ensure it's iterable\n",
    "\n",
    "                for i, col in enumerate(self.ik_columns):\n",
    "                    ax = axes[i]\n",
    "\n",
    "                    # Plot mean line\n",
    "                    ax.plot(time_values, mean_values[:, i], color='red', label=\"Mean\", linewidth=2)\n",
    "\n",
    "                    # Shade the standard deviation range\n",
    "                    ax.fill_between(time_values, mean_values[:, i] - std_values[:, i],\n",
    "                                    mean_values[:, i] + std_values[:, i], color='red', alpha=0.2, label=\"SD Range\")\n",
    "\n",
    "                    # Formatting\n",
    "                    ax.set_title(col)\n",
    "                    ax.set_xlabel(\"Gait Cycle (%)\")\n",
    "                    ax.set_xlim(0, 100)  # X-axis from 0% to 100% of the gait cycle\n",
    "                    ax.grid(True)\n",
    "\n",
    "                    # Set Y-label only for the first subplot\n",
    "                    if i == 0:\n",
    "                        ax.set_ylabel(\"Angle (Degrees)\")\n",
    "                        ax.legend()\n",
    "\n",
    "\n",
    "                plt.tight_layout()\n",
    "\n",
    "                if show:\n",
    "                    plt.show()\n",
    "\n",
    "def export_c3d(c3dFilePath):\n",
    "    analog_file_path = os.path.join(os.path.dirname(c3dFilePath),'analog.csv')\n",
    "    \n",
    "    # if the file already exists, return the file\n",
    "    if os.path.isfile(analog_file_path):\n",
    "        df = msk.pd.read_csv(analog_file_path)\n",
    "        return df\n",
    "    \n",
    "    print('Exporting analog data to csv ...')\n",
    "    \n",
    "    # read c3d file\n",
    "    reader = c3d.Reader(open(c3dFilePath, 'rb'))\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    analog_labels = reader.analog_labels\n",
    "    analog_labels = [label.strip() for label in analog_labels]\n",
    "    analog_labels = [label.replace('.', '_') for label in analog_labels]\n",
    "\n",
    "    # get analog labels, trimmed and replace '.' with '_'\n",
    "    first_frame = reader.first_frame\n",
    "    num_frames = reader.frame_count\n",
    "    fs = reader.analog_rate\n",
    "\n",
    "    # add time to dataframe\n",
    "    initial_time = first_frame / fs\n",
    "    final_time = (first_frame + num_frames-1) / fs\n",
    "    time = np.arange(first_frame / fs, final_time, 1 / fs) \n",
    "\n",
    "    df = msk.pd.DataFrame(index=range(num_frames),columns=analog_labels)\n",
    "    df['time'] = time\n",
    "    \n",
    "    # move time to first column\n",
    "    cols = df.columns.tolist()\n",
    "    cols = cols[-1:] + cols[:-1]\n",
    "    df = df[cols]    \n",
    "    \n",
    "    # loop through frames and add analog data to dataframe\n",
    "    for i_frame, points, analog in reader.read_frames():\n",
    "        \n",
    "        # get row number and print loading bar\n",
    "        i_row = i_frame - reader.first_frame\n",
    "        # msk.ut.print_loading_bar(i_row/num_frames)\n",
    "        \n",
    "        # convert analog data to list\n",
    "        analog_list  = analog.data.tolist()\n",
    "        \n",
    "        # loop through analog channels and add to dataframe\n",
    "        for i_channel in range(len(analog_list)):\n",
    "            channel_name = analog_labels[i_channel]\n",
    "            \n",
    "            # add channel to dataframe\n",
    "            df.loc[i_row, channel_name] = analog[i_channel][0]\n",
    "    \n",
    "    # save emg data to csv   \n",
    "    df.to_csv(analog_file_path)\n",
    "    print('analog.csv exported to ' + analog_file_path)  \n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file does not exist\n",
      "file extension does not match any of the bops options\n",
      "file extension does not match any of the bops options\n",
      "file extension does not match any of the bops options\n",
      "file extension does not match any of the bops options\n",
      "file extension does not match any of the bops options\n",
      "file extension does not match any of the bops options\n"
     ]
    }
   ],
   "source": [
    "trial_path = msk.ui.select_folder('Select trial folder')\n",
    "trial = msk.classes.Trial(trial_path=trial_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial.files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "msk_modelling",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
